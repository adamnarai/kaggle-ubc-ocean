{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.vision.widgets import *\n",
    "from torchvision.models import get_model\n",
    "import wandb\n",
    "\n",
    "# Params\n",
    "Image.MAX_IMAGE_PIXELS = 1e11\n",
    "CFG = {\n",
    "    'base_model': 'efficientnet_v2_s',   # resnet18/34/50, efficientnet_v2_s/m/l\n",
    "    'batch_size': 32,\n",
    "    'whole_img_size': 700,\n",
    "    'aug_img_size': 512,\n",
    "    'aug_min_scale': 1.0,\n",
    "    'freeze_epochs': 1,\n",
    "    'epochs': 10,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Wandb\n",
    "wandb.login(key='1b0401db7513303bdea77fb070097f9d2850cf3b')\n",
    "run = wandb.init(project='kaggle-ubc-ocean', config=CFG, tags=['fastai', 'baseline'])\n",
    "\n",
    "# Paths\n",
    "root = '/media/latlab/MR/projects/kaggle-ubc-ocean'\n",
    "data_dir = os.path.join(root, 'data')\n",
    "results_dir = os.path.join(root, 'results')\n",
    "train_filename = 'train.csv'\n",
    "train_img_dir = os.path.join(data_dir, 'train_images')\n",
    "train_thumbnail_dir = os.path.join(data_dir, 'train_thumbnails')\n",
    "\n",
    "# Functions\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def get_file_path(image_id):\n",
    "    if os.path.exists(os.path.join(train_thumbnail_dir, f'{image_id}_thumbnail.png')):\n",
    "        return os.path.join(train_thumbnail_dir, f'{image_id}_thumbnail.png')\n",
    "    else:\n",
    "        return os.path.join(train_img_dir, f'{image_id}.png')\n",
    "\n",
    "# Seed\n",
    "seed_everything(CFG['seed'])\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Load descriptive data\n",
    "df = pd.read_csv(os.path.join(data_dir, train_filename))\n",
    "\n",
    "# Add image path\n",
    "df['image_path'] = df['image_id'].apply(get_file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SideCrop(Transform):\n",
    "    def __init__(self): pass\n",
    "    def encodes(self, image: PILImage):\n",
    "        size = min(image.size)\n",
    "        new_image = image.crop_pad((size, size), (0,0))\n",
    "        return new_image\n",
    "    \n",
    "dblock = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "            get_x=ColReader('image_path'),\n",
    "            get_y=ColReader('label'),\n",
    "            splitter=RandomSplitter(valid_pct=0.2, seed=CFG['seed']),\n",
    "            item_tfms=[SideCrop(), Resize(CFG['whole_img_size'], method='crop')],\n",
    "            batch_tfms=[*aug_transforms(size=CFG['aug_img_size'], min_scale=CFG['aug_min_scale'], max_warp=0), Normalize.from_stats(*imagenet_stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dls = dblock.dataloaders(df, bs=CFG['batch_size'], num_workers=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, eval(CFG['base_model']), metrics=BalancedAccuracy())\n",
    "learn.fine_tune(CFG['epochs'], freeze_epochs=CFG['freeze_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in learn.recorder.values:\n",
    "    wandb.log({'train_loss': res[0], \n",
    "               'valid_loss': res[1],\n",
    "               'balanced_accuracy': res[2]})\n",
    "wandb.finish()\n",
    "learn.export(os.path.join(results_dir, 'models', f'ubc-ocean_{run.name}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show accuracy plot\n",
    "plt.plot(np.array(learn.recorder.values)[:,2])\n",
    "plt.figure()\n",
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()\n",
    "# interp.most_confused(min_val=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(18, nrows=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubc-ocean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
