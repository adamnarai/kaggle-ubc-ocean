{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "\n",
    "from dataset import get_dataloaders, get_tiles_datasets\n",
    "from utils import seed_everything\n",
    "from trainer import Trainer\n",
    "\n",
    "# Params\n",
    "Image.MAX_IMAGE_PIXELS = 1e11\n",
    "CFG = {\n",
    "    'seed': 42,\n",
    "    'cv_fold': 5,\n",
    "    'base_model': 'convnext_tiny',   # resnet18/34/50, efficientnet_b0/b1/b2/b3/b4, efficientnet_v2_s, convnext_tiny, swin_t\n",
    "    'img_size': 512,\n",
    "    'batch_size': 32,\n",
    "    'freeze_epochs': 1,\n",
    "    'epochs': 5,\n",
    "    'base_lr': 1e-4,\n",
    "    'affine_degrees': 0,\n",
    "    'affine_translate': None,\n",
    "    'affine_scale': None,\n",
    "    'dataloader_num_workers': 8,\n",
    "    'scheduler_step_size': 2,\n",
    "    'img_color_mean': [0.8708488980328596, 0.75677901508938, 0.8545134911215124],\n",
    "    'img_color_std': [0.08086288591996027, 0.11553960008706814, 0.06914169213328555],\n",
    "    'tile_num': 32,\n",
    "    'optimizer': 'AdamW',\n",
    "    'scheduler': 'StepLR',\n",
    "    'loss': 'CrossEntropyLoss',\n",
    "    'label_smoothing': 0,\n",
    "    'lr_gamma': 0.1,\n",
    "    'sgd_momentum': 0.9,\n",
    "    'valid_type': 'all_tmas',\n",
    "    'tile_set': 'train_tiles_1024_p50_drop60_v6',\n",
    "    'tile_table_postfix': '_only_tumor_v2', # '_only_tumor' '_only_tumor_v2'\n",
    "    'color_jitter': {'brightness': 0.2, 'contrast': 0.2, 'saturation': 0.2, 'hue': 0.2},\n",
    "    'random_erasing_p': 0,\n",
    "    'fc_2_in_features': 512,\n",
    "    'fc_dropout': 0.2\n",
    "}\n",
    "tags=['torch', 'tiles', 'cv', 'best_epoch']\n",
    "notes = 'extended double layer head'\n",
    "plot_samples = False\n",
    "train_final_model = True\n",
    "\n",
    "# Wandb\n",
    "wandb.login()\n",
    "run = wandb.init(project='kaggle-ubc-ocean', config=CFG, tags=tags, notes=notes)\n",
    "\n",
    "# Label encoder/decoder\n",
    "encode = {'HGSC': 0, 'LGSC': 1, 'EC': 2, 'CC': 3, 'MC': 4}\n",
    "decode = {v: k for k, v in encode.items()}\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Paths\n",
    "root = '/media/latlab/MR/projects/kaggle-ubc-ocean'\n",
    "data_dir = os.path.join(root, 'data')\n",
    "results_dir = os.path.join(root, 'results')\n",
    "train_image_dir = os.path.join(results_dir, CFG['tile_set'])\n",
    "train_csv = '{}_sample{}.csv'.format(CFG['tile_set']+CFG['tile_table_postfix'], CFG['tile_num'])\n",
    "\n",
    "# Seed\n",
    "seed_everything(CFG['seed'])\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(os.path.join(results_dir, train_csv))\n",
    "df['label'] = df.loc[:,'label'].map(encode)\n",
    "\n",
    "# Functions\n",
    "def train_model(CFG, train_image_dir, df_train, df_validation, encode, state_filename, validate=True, wandb_log=False):\n",
    "    # Data loaders\n",
    "    datasets = get_tiles_datasets(CFG, train_image_dir, df_train, df_validation)\n",
    "    dataloaders = get_dataloaders(CFG, datasets)\n",
    "\n",
    "    # Model definition\n",
    "    model = models.get_model(CFG['base_model'], weights='DEFAULT').to(device)\n",
    "\n",
    "    # Freeze all parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Replace the classifier layer\n",
    "    if CFG['base_model'].startswith('resnet'):\n",
    "        model.fc = nn.Linear(in_features=model.fc.in_features, out_features=len(encode)).to(device)\n",
    "    elif CFG['base_model'].startswith('efficientnet'):\n",
    "        model.classifier[1] = nn.Linear(in_features=model.classifier[1].in_features, out_features=len(encode), bias=True).to(device)\n",
    "    elif CFG['base_model'].startswith('convnext'):\n",
    "        model.classifier[2] = nn.Linear(in_features=model.classifier[2].in_features, out_features=len(encode), bias=True).to(device)\n",
    "    elif CFG['base_model'].startswith('vit'):\n",
    "        model.heads.head = nn.Linear(in_features=model.heads.head.in_features, out_features=len(encode), bias=True).to(device)\n",
    "    elif CFG['base_model'].startswith('swin'):\n",
    "        model.head = nn.Linear(in_features=model.head.in_features, out_features=len(encode), bias=True).to(device)\n",
    "    else:\n",
    "        raise NotImplementedError('Classifier layer replacement not implemented for this model')\n",
    "    \n",
    "    # Loss function\n",
    "    if CFG['loss'] == 'CrossEntropyLoss':\n",
    "        loss_fn = nn.CrossEntropyLoss(label_smoothing=CFG['label_smoothing'])\n",
    "    elif CFG['loss'] == 'BCEWithLogitsLoss':\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Optimizer\n",
    "    if CFG['optimizer'] == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=CFG['base_lr'], momentum=CFG['sgd_momentum'])\n",
    "    elif CFG['optimizer'] == 'AdamW':\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=CFG['base_lr'])\n",
    "    elif CFG['optimizer'] == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=CFG['base_lr'])\n",
    "    \n",
    "    # Scheduler\n",
    "    if CFG['scheduler'] == 'StepLR':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=CFG['scheduler_step_size'], gamma=CFG['lr_gamma'], verbose=True)\n",
    "    elif CFG['scheduler'] == 'CyclicLR':\n",
    "        scheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr=CFG['base_lr'], max_lr=CFG['base_lr']*5,\n",
    "                                                step_size_up=5, cycle_momentum=False, mode='triangular2', verbose=True)\n",
    "    elif CFG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG['epochs']+CFG['freeze_epochs'], verbose=True)\n",
    "    elif CFG['scheduler'] == 'OneCycleLR':\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=CFG['base_lr'], total_steps=CFG['epochs']+CFG['freeze_epochs'], verbose=True)\n",
    "\n",
    "    # Training\n",
    "    trainer = Trainer(model, dataloaders, loss_fn, optimizer, scheduler, device, state_filename=state_filename, metric='balanced_accuracy', wandb_log=wandb_log)\n",
    "    trainer.train_epochs(num_epochs=CFG['freeze_epochs'], validate=validate)\n",
    "    trainer.unfreeze()\n",
    "    trainer.train_epochs(num_epochs=CFG['epochs'], validate=validate)\n",
    "    trainer.save_state(state_filename)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training data\n",
    "if plot_samples:\n",
    "    dataloaders = get_dataloaders(CFG, get_tiles_datasets(CFG, train_image_dir, df, df))\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloaders['train']):\n",
    "            plt.figure(figsize=(np.ceil(len(X)/2), 12))\n",
    "            for i in range(len(X)):\n",
    "                plt.subplot(int(np.ceil(len(X)/6)), 6, i+1)\n",
    "                img_data = X[i].permute(1, 2, 0).cpu().numpy()\n",
    "                # Normalize images for plotting (since there are negative values in tensors)\n",
    "                img_data_norm = np.clip(((img_data - img_data.mean(axis=(0, 1, 2))) / img_data.std(axis=(0, 1, 2)))/4 + 0.5, 0, 1)\n",
    "                plt.imshow(img_data_norm)\n",
    "                plt.title(f'{decode[y[i].item()]}')\n",
    "            if batch >= 1:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedGroupKFold(n_splits=CFG['cv_fold'], random_state=CFG['seed'], shuffle=True)\n",
    "balanced_acc_list = []\n",
    "if CFG['valid_type'] == 'all_tmas':\n",
    "    df_tma = df[df['is_tma']==True].copy().reset_index(drop=True)\n",
    "    df_wsi = df[df['is_tma']==False].copy().reset_index(drop=True)\n",
    "    for cv, (train_index, valid_index) in enumerate(skf.split(X=np.zeros(len(df_wsi['label'])), y=df_wsi['label'], groups=df_wsi['orig_image_id'])):\n",
    "        print(f\"Cross-validation fold {cv+1}/{CFG['cv_fold']}\")\n",
    "        df_train = df_wsi.iloc[train_index]\n",
    "        df_validation = df_wsi.iloc[valid_index]\n",
    "        df_validation = pd.concat([df_validation, df_tma], ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
    "        run_name = f'{run.name}-cv{cv+1}'\n",
    "        state_filename = os.path.join(results_dir, 'models', f'ubc-ocean-{run_name}.pt')\n",
    "        trainer = train_model(CFG, train_image_dir, df_train, df_validation, encode, state_filename)\n",
    "        balanced_acc_list.append(trainer.best_metric)\n",
    "        wandb.log({f'balanced_acc_cv{cv+1}': trainer.best_metric})\n",
    "elif CFG['valid_type'] == 'standard':\n",
    "    for cv, (train_index, valid_index) in enumerate(skf.split(X=np.zeros(len(df['label'])), y=df['label'], groups=df['orig_image_id'])):\n",
    "        print(f\"Cross-validation fold {cv+1}/{CFG['cv_fold']}\")\n",
    "        df_train = df.iloc[train_index]\n",
    "        df_validation = df.iloc[valid_index]\n",
    "        run_name = f'{run.name}-cv{cv+1}'\n",
    "        state_filename = os.path.join(results_dir, 'models', f'ubc-ocean-{run_name}.pt')\n",
    "        trainer = train_model(CFG, train_image_dir, df_train, df_validation, encode, state_filename)\n",
    "        balanced_acc_list.append(trainer.best_metric)\n",
    "        wandb.log({f'balanced_acc_cv{cv+1}': trainer.best_metric})\n",
    "wandb.log({f'mean_balanced_acc': np.mean(balanced_acc_list)})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final training on all data\n",
    "if train_final_model:\n",
    "    state_filename = os.path.join(results_dir, 'models', f'ubc-ocean-{run.name}.pt')\n",
    "    trainer = train_model(CFG, train_image_dir, df, df, encode, state_filename, validate=False, wandb_log=False)\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubc-ocean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
