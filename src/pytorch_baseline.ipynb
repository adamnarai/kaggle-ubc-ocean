{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "\n",
    "from dataset import get_dataloaders, get_datasets\n",
    "from utils import seed_everything\n",
    "from trainer import Trainer\n",
    "\n",
    "# Params\n",
    "Image.MAX_IMAGE_PIXELS = 1e11\n",
    "CFG = {\n",
    "    'seed': 42,\n",
    "    'base_model': 'resnet18',\n",
    "    'img_size': 512,\n",
    "    'batch_size': 32,\n",
    "    'freeze_epochs': 1,\n",
    "    'epochs': 10,\n",
    "    'base_lr': 1e-3,\n",
    "    'affine_degrees': 0,\n",
    "    'affine_translate': None,\n",
    "    'affine_scale': None,\n",
    "    'cv_fold': 5,\n",
    "}\n",
    "\n",
    "# Wandb\n",
    "wandb.login(key='1b0401db7513303bdea77fb070097f9d2850cf3b')\n",
    "run = wandb.init(project='kaggle-ubc-ocean', config=CFG, tags=['torch', 'baseline'])\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Paths\n",
    "root = '/media/latlab/MR/projects/kaggle-ubc-ocean'\n",
    "data_dir = os.path.join(root, 'data')\n",
    "results_dir = os.path.join(root, 'results')\n",
    "train_csv = 'train.csv'\n",
    "train_image_dir = os.path.join(data_dir, 'train_images')\n",
    "train_thumbnail_dir = os.path.join(data_dir, 'train_thumbnails')\n",
    "\n",
    "# Seed\n",
    "seed_everything(CFG['seed'])\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(os.path.join(data_dir, train_csv))\n",
    "\n",
    "# # Train/validation split\n",
    "# df_train, df_validation = train_test_split(df, test_size=0.2, stratify=df['label'], shuffle=True, random_state=CFG['seed'])\n",
    "\n",
    "# Label encoder/decoder\n",
    "encode = {v: k for k, v in enumerate(df.label.unique())}\n",
    "decode = {v: k for k, v in encode.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(CFG, train_image_dir, train_thumbnail_dir, df_train, df_validation, encode):\n",
    "    # Data loaders\n",
    "    datasets = get_datasets(CFG, train_image_dir, train_thumbnail_dir, df_train, df_validation, encode)\n",
    "    dataloaders = get_dataloaders(CFG, datasets)\n",
    "\n",
    "    # Model definition\n",
    "    model = models.get_model(CFG['base_model'], weights='DEFAULT').to(device)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(encode)).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=CFG['base_lr'], momentum=0.9)\n",
    "    exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    # Training\n",
    "    trainer = Trainer(model, dataloaders, loss_fn, optimizer, exp_lr_scheduler, device)\n",
    "    model, _ = trainer.train(num_epochs=CFG['freeze_epochs'])\n",
    "    trainer.unfreeze()\n",
    "    model, best_balanced_acc = trainer.train(num_epochs=CFG['epochs'])\n",
    "    return model, best_balanced_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=CFG['cv_fold'], random_state=CFG['seed'], shuffle=True)\n",
    "balanced_acc_list = []\n",
    "lb = df['label']\n",
    "for cv, (train_index, valid_index) in enumerate(skf.split(np.zeros(len(lb)), lb)):\n",
    "    df_train = df.iloc[train_index]\n",
    "    df_validation = df.iloc[valid_index]\n",
    "    run_name = f'{run.name}-cv{cv+1}'\n",
    "    model, best_balanced_acc = train_model(CFG, train_image_dir, train_thumbnail_dir, df_train, df_validation, encode)\n",
    "    balanced_acc_list.append(best_balanced_acc)\n",
    "    torch.save(model.state_dict(), os.path.join(results_dir, 'models', f'ubc-ocean_{run_name}.pt'))\n",
    "    wandb.log({f'best_balanced_acc_cv{cv}': best_balanced_acc})\n",
    "wandb.log({f'mean_best_balanced_acc_cv{cv}': np.mean(balanced_acc_list)})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model\n",
    "# torch.save(model.state_dict(), os.path.join(results_dir, 'models', f'ubc-ocean_{run.name}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Plot samples\n",
    "# fig = plt.figure(figsize=(16, 16))\n",
    "# for i, sample in enumerate(dataset):\n",
    "#     ax = plt.subplot(10, 10, i + 1)\n",
    "#     plt.imshow(sample['image'])\n",
    "#     ax.axis('off')\n",
    "#     plt.title(f\"#{i} {sample['label']}\")\n",
    "\n",
    "#     if i==99:\n",
    "#         plt.show()\n",
    "#         break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubc-ocean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
