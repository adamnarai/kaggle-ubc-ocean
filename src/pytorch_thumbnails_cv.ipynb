{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaraiadam88\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/latlab/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/latlab/MR/projects/kaggle-ubc-ocean/src/wandb/run-20231204_223845-ym414o73</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/naraiadam88/kaggle-ubc-ocean/runs/ym414o73' target=\"_blank\">fine-sun-357</a></strong> to <a href='https://wandb.ai/naraiadam88/kaggle-ubc-ocean' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/naraiadam88/kaggle-ubc-ocean' target=\"_blank\">https://wandb.ai/naraiadam88/kaggle-ubc-ocean</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/naraiadam88/kaggle-ubc-ocean/runs/ym414o73' target=\"_blank\">https://wandb.ai/naraiadam88/kaggle-ubc-ocean/runs/ym414o73</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "\n",
    "from dataset import get_dataloaders, get_datasets\n",
    "from utils import seed_everything\n",
    "from trainer import Trainer\n",
    "\n",
    "# Params\n",
    "Image.MAX_IMAGE_PIXELS = 1e11\n",
    "CFG = {\n",
    "    'seed': 42,\n",
    "    'cv_fold': 5,\n",
    "    'base_model': 'convnext_tiny',   # resnet18/34/50, efficientnet_b0/b1/b2/b3/b4, convnext_tiny, vit_b_16, swin_t\n",
    "    'img_size': 1024,\n",
    "    'batch_size': 16,\n",
    "    'freeze_epochs': 1,\n",
    "    'epochs': 5,\n",
    "    'base_lr': 3e-4,\n",
    "    'affine_degrees': 10,\n",
    "    'affine_translate': (0.1, 0.1),\n",
    "    'affine_scale': (1, 1.4),\n",
    "    'dataloader_num_workers': 8,\n",
    "    'scheduler_step_size': 2,\n",
    "    'img_color_mean': [0.8708488980328596, 0.75677901508938, 0.8545134911215124],\n",
    "    'img_color_std': [0.08086288591996027, 0.11553960008706814, 0.06914169213328555],\n",
    "    'optimizer': 'AdamW',\n",
    "    'scheduler': 'CosineAnnealingLR',\n",
    "    'lr_gamma': 0.1,\n",
    "    'lr_cycl_step_size': 3,\n",
    "    'sgd_momentum': 0.9,\n",
    "    'valid_type': 'standard'\n",
    "    # 'hed_theta': 0.01,\n",
    "    # 'color_jitter': {'brightness': 0.2, 'saturation': 0.2, 'hue': 0.1}\n",
    "}\n",
    "tags = ['torch', 'thumbnails', 'cv']\n",
    "notes = ''\n",
    "plot_samples = False\n",
    "\n",
    "# Wandb\n",
    "wandb.login(key='1b0401db7513303bdea77fb070097f9d2850cf3b')\n",
    "run = wandb.init(project='kaggle-ubc-ocean', config=CFG, tags=tags, notes=notes)\n",
    "\n",
    "# Label encoder/decoder\n",
    "encode = {'HGSC': 0, 'LGSC': 1, 'EC': 2, 'CC': 3, 'MC': 4}\n",
    "decode = {v: k for k, v in encode.items()}\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Paths\n",
    "root = '/media/latlab/MR/projects/kaggle-ubc-ocean'\n",
    "data_dir = os.path.join(root, 'data')\n",
    "results_dir = os.path.join(root, 'results')\n",
    "train_csv = 'train.csv'\n",
    "train_image_dir = os.path.join(data_dir, 'train_images')\n",
    "train_thumbnail_dir = os.path.join(data_dir, 'train_thumbnails')\n",
    "\n",
    "# Seed\n",
    "seed_everything(CFG['seed'])\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(os.path.join(data_dir, train_csv))\n",
    "df['label'] = df.loc[:,'label'].map(encode)\n",
    "\n",
    "# Functions\n",
    "def train_model(CFG, train_image_dir, train_thumbnail_dir, df_train, df_validation, encode, wandb_log=False):\n",
    "    # Data loaders\n",
    "    datasets = get_datasets(CFG, train_image_dir, train_thumbnail_dir, df_train, df_validation)\n",
    "    dataloaders = get_dataloaders(CFG, datasets)\n",
    "\n",
    "    # Model definition\n",
    "    model = models.get_model(CFG['base_model'], weights='DEFAULT').to(device)\n",
    "\n",
    "    # Freeze all parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Replace the last fully-connected layer\n",
    "    if CFG['base_model'].startswith('resnet'):\n",
    "        model.fc = nn.Linear(in_features=model.fc.in_features, out_features=len(encode)).to(device)\n",
    "    elif CFG['base_model'].startswith('efficientnet'):\n",
    "        model.classifier[1] = nn.Linear(in_features=model.classifier[1].in_features, out_features=len(encode), bias=True).to(device)\n",
    "    elif CFG['base_model'].startswith('convnext'):\n",
    "        model.classifier[2] = nn.Linear(in_features=model.classifier[2].in_features, out_features=len(encode), bias=True).to(device)\n",
    "    elif CFG['base_model'].startswith('vit'):\n",
    "        model.heads.head = nn.Linear(in_features=model.heads.head.in_features, out_features=len(encode), bias=True).to(device)\n",
    "    elif CFG['base_model'].startswith('swin'):\n",
    "        model.head = nn.Linear(in_features=model.head.in_features, out_features=len(encode), bias=True).to(device)\n",
    "    \n",
    "    # Loss function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Optimizer\n",
    "    if CFG['optimizer'] == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=CFG['base_lr'], momentum=CFG['sgd_momentum'])\n",
    "    elif CFG['optimizer'] == 'AdamW':\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=CFG['base_lr'])\n",
    "    elif CFG['optimizer'] == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=CFG['base_lr'])\n",
    "    \n",
    "    # Scheduler\n",
    "    if CFG['scheduler'] == 'StepLR':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=CFG['scheduler_step_size'], gamma=CFG['lr_gamma'], verbose=True)\n",
    "    elif CFG['scheduler'] == 'CyclicLR':\n",
    "        scheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr=CFG['base_lr'], max_lr=CFG['base_lr']*10,\n",
    "                                                step_size_up=3, cycle_momentum=False, mode='triangular2', verbose=True)\n",
    "    elif CFG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG['epochs']+CFG['freeze_epochs'], verbose=True)\n",
    "    elif CFG['scheduler'] == 'OneCycleLR':\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=CFG['base_lr'], total_steps=CFG['epochs']+CFG['freeze_epochs'], verbose=True)\n",
    "\n",
    "    # Training\n",
    "    trainer = Trainer(model, dataloaders, loss_fn, optimizer, scheduler, device, metric='balanced_accuracy', wandb_log=wandb_log)\n",
    "    model, _ = trainer.train_epochs(num_epochs=CFG['freeze_epochs'])\n",
    "    trainer.unfreeze()\n",
    "    model, balanced_acc = trainer.train_epochs(num_epochs=CFG['epochs'])\n",
    "    return model, balanced_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training data\n",
    "if plot_samples:\n",
    "    dataloaders = get_dataloaders(CFG, get_datasets(CFG, train_image_dir, train_thumbnail_dir, df, df))\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloaders['train']):\n",
    "            plt.figure(figsize=(16, 12))\n",
    "            for i in range(len(X)):\n",
    "                plt.subplot(int(np.ceil(len(X)/6)), 6, i+1)\n",
    "                img_data = X[i].permute(1, 2, 0).cpu().numpy()\n",
    "                plt.imshow(img_data)\n",
    "                plt.title(f'{decode[y[i].item()]}')\n",
    "            if batch >= 1:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation fold 1/5\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:40<00:00,  1.48s/it]\n",
      "100%|██████████| 7/7 [00:12<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.3301e-05.\n",
      "train loss: 1.5182, test loss: 1.4519, balanced_accuracy: 0.2285\n",
      "\n",
      "Training complete in 0m 53s\n",
      "Final balanced_accuracy: 0.228486\n",
      "\n",
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:45<00:00,  1.70s/it]\n",
      "100%|██████████| 7/7 [00:12<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.5000e-05.\n",
      "train loss: 1.3861, test loss: 1.3356, balanced_accuracy: 0.3825\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:44<00:00,  1.63s/it]\n",
      "100%|██████████| 7/7 [00:12<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "train loss: 1.1205, test loss: 1.2030, balanced_accuracy: 0.4733\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:44<00:00,  1.66s/it]\n",
      "100%|██████████| 7/7 [00:12<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.5000e-05.\n",
      "train loss: 0.8884, test loss: 0.9278, balanced_accuracy: 0.5670\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:46<00:00,  1.72s/it]\n",
      "100%|██████████| 7/7 [00:12<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.6987e-06.\n",
      "train loss: 0.7259, test loss: 0.9208, balanced_accuracy: 0.6445\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:44<00:00,  1.65s/it]\n",
      "100%|██████████| 7/7 [00:12<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 0.0000e+00.\n",
      "train loss: 0.6107, test loss: 0.9024, balanced_accuracy: 0.6438\n",
      "\n",
      "Training complete in 4m 49s\n",
      "Final balanced_accuracy: 0.643849\n",
      "\n",
      "Cross-validation fold 2/5\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:43<00:00,  1.60s/it]\n",
      "100%|██████████| 7/7 [00:11<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.3301e-05.\n",
      "train loss: 1.6112, test loss: 1.5595, balanced_accuracy: 0.1818\n",
      "\n",
      "Training complete in 0m 54s\n",
      "Final balanced_accuracy: 0.181780\n",
      "\n",
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:46<00:00,  1.72s/it]\n",
      "100%|██████████| 7/7 [00:11<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.5000e-05.\n",
      "train loss: 1.3422, test loss: 1.1824, balanced_accuracy: 0.4926\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:46<00:00,  1.71s/it]\n",
      "100%|██████████| 7/7 [00:11<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "train loss: 1.0478, test loss: 0.9624, balanced_accuracy: 0.6619\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:47<00:00,  1.74s/it]\n",
      "100%|██████████| 7/7 [00:11<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.5000e-05.\n",
      "train loss: 0.8203, test loss: 0.8845, balanced_accuracy: 0.6149\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:44<00:00,  1.66s/it]\n",
      "100%|██████████| 7/7 [00:11<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.6987e-06.\n",
      "train loss: 0.6677, test loss: 0.9725, balanced_accuracy: 0.6514\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:45<00:00,  1.69s/it]\n",
      "100%|██████████| 7/7 [00:11<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 0.0000e+00.\n",
      "train loss: 0.5411, test loss: 0.8439, balanced_accuracy: 0.6840\n",
      "\n",
      "Training complete in 4m 46s\n",
      "Final balanced_accuracy: 0.684037\n",
      "\n",
      "Cross-validation fold 3/5\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:39<00:00,  1.46s/it]\n",
      "100%|██████████| 7/7 [00:11<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.3301e-05.\n",
      "train loss: 1.6114, test loss: 1.5217, balanced_accuracy: 0.2557\n",
      "\n",
      "Training complete in 0m 50s\n",
      "Final balanced_accuracy: 0.255714\n",
      "\n",
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:45<00:00,  1.70s/it]\n",
      "100%|██████████| 7/7 [00:11<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.5000e-05.\n",
      "train loss: 1.3716, test loss: 1.1949, balanced_accuracy: 0.4474\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:44<00:00,  1.66s/it]\n",
      "100%|██████████| 7/7 [00:11<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "train loss: 1.0470, test loss: 1.1218, balanced_accuracy: 0.5487\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:46<00:00,  1.73s/it]\n",
      "100%|██████████| 7/7 [00:11<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.5000e-05.\n",
      "train loss: 0.9798, test loss: 0.8833, balanced_accuracy: 0.5810\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:47<00:00,  1.76s/it]\n",
      "100%|██████████| 7/7 [00:11<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.6987e-06.\n",
      "train loss: 0.7497, test loss: 0.8953, balanced_accuracy: 0.6327\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:45<00:00,  1.68s/it]\n",
      "100%|██████████| 7/7 [00:11<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 0.0000e+00.\n",
      "train loss: 0.6524, test loss: 0.8352, balanced_accuracy: 0.6618\n",
      "\n",
      "Training complete in 4m 46s\n",
      "Final balanced_accuracy: 0.661786\n",
      "\n",
      "Cross-validation fold 4/5\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:37<00:00,  1.40s/it]\n",
      "100%|██████████| 7/7 [00:13<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.3301e-05.\n",
      "train loss: 1.5506, test loss: 1.5269, balanced_accuracy: 0.1996\n",
      "\n",
      "Training complete in 0m 51s\n",
      "Final balanced_accuracy: 0.199575\n",
      "\n",
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:43<00:00,  1.63s/it]\n",
      "100%|██████████| 7/7 [00:13<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.5000e-05.\n",
      "train loss: 1.3312, test loss: 1.1776, balanced_accuracy: 0.3878\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:45<00:00,  1.68s/it]\n",
      "100%|██████████| 7/7 [00:13<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "train loss: 0.9847, test loss: 1.0701, balanced_accuracy: 0.5144\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:45<00:00,  1.70s/it]\n",
      "100%|██████████| 7/7 [00:13<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.5000e-05.\n",
      "train loss: 0.7756, test loss: 1.0181, balanced_accuracy: 0.5518\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:45<00:00,  1.70s/it]\n",
      "100%|██████████| 7/7 [00:13<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.6987e-06.\n",
      "train loss: 0.6368, test loss: 1.0168, balanced_accuracy: 0.5482\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:43<00:00,  1.62s/it]\n",
      "100%|██████████| 7/7 [00:13<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 0.0000e+00.\n",
      "train loss: 0.5235, test loss: 0.9446, balanced_accuracy: 0.5932\n",
      "\n",
      "Training complete in 4m 51s\n",
      "Final balanced_accuracy: 0.593197\n",
      "\n",
      "Cross-validation fold 5/5\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:37<00:00,  1.38s/it]\n",
      "100%|██████████| 7/7 [00:13<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.3301e-05.\n",
      "train loss: 1.5413, test loss: 1.4570, balanced_accuracy: 0.2830\n",
      "\n",
      "Training complete in 0m 51s\n",
      "Final balanced_accuracy: 0.282959\n",
      "\n",
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:44<00:00,  1.64s/it]\n",
      "100%|██████████| 7/7 [00:13<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.5000e-05.\n",
      "train loss: 1.3517, test loss: 1.0635, balanced_accuracy: 0.4803\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:44<00:00,  1.66s/it]\n",
      "100%|██████████| 7/7 [00:13<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "train loss: 1.0214, test loss: 1.0432, balanced_accuracy: 0.5392\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:45<00:00,  1.68s/it]\n",
      "100%|██████████| 7/7 [00:13<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.5000e-05.\n",
      "train loss: 0.8437, test loss: 0.6976, balanced_accuracy: 0.7250\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:45<00:00,  1.69s/it]\n",
      "100%|██████████| 7/7 [00:13<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.6987e-06.\n",
      "train loss: 0.6735, test loss: 0.6945, balanced_accuracy: 0.7127\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:45<00:00,  1.67s/it]\n",
      "100%|██████████| 7/7 [00:13<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 0.0000e+00.\n",
      "train loss: 0.5873, test loss: 0.6527, balanced_accuracy: 0.7015\n",
      "\n",
      "Training complete in 4m 53s\n",
      "Final balanced_accuracy: 0.701497\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>balanced_acc_cv1</td><td>▁</td></tr><tr><td>balanced_acc_cv2</td><td>▁</td></tr><tr><td>balanced_acc_cv3</td><td>▁</td></tr><tr><td>balanced_acc_cv4</td><td>▁</td></tr><tr><td>balanced_acc_cv5</td><td>▁</td></tr><tr><td>mean_balanced_acc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>balanced_acc_cv1</td><td>0.64385</td></tr><tr><td>balanced_acc_cv2</td><td>0.68404</td></tr><tr><td>balanced_acc_cv3</td><td>0.66179</td></tr><tr><td>balanced_acc_cv4</td><td>0.5932</td></tr><tr><td>balanced_acc_cv5</td><td>0.7015</td></tr><tr><td>mean_balanced_acc</td><td>0.65687</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fine-sun-357</strong> at: <a href='https://wandb.ai/naraiadam88/kaggle-ubc-ocean/runs/ym414o73' target=\"_blank\">https://wandb.ai/naraiadam88/kaggle-ubc-ocean/runs/ym414o73</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231204_223845-ym414o73/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=CFG['cv_fold'], random_state=CFG['seed'], shuffle=True)\n",
    "balanced_acc_list = []\n",
    "if CFG['valid_type'] == 'all_tmas':\n",
    "    df_tma = df[df['is_tma']==True].copy().reset_index(drop=True)\n",
    "    df_wsi = df[df['is_tma']==False].copy().reset_index(drop=True)\n",
    "    for cv, (train_index, valid_index) in enumerate(skf.split(X=np.zeros(len(df_wsi['label'])), y=df_wsi['label'])):\n",
    "        print(f\"Cross-validation fold {cv+1}/{CFG['cv_fold']}\")\n",
    "        df_train = df_wsi.iloc[train_index]\n",
    "        df_validation = df_wsi.iloc[valid_index]\n",
    "        df_validation = pd.concat([df_validation, df_tma], ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
    "        run_name = f'{run.name}-cv{cv+1}'\n",
    "        model, balanced_acc = train_model(CFG, train_image_dir, train_thumbnail_dir, df_train, df_validation, encode)\n",
    "        balanced_acc_list.append(balanced_acc)\n",
    "        torch.save(model.state_dict(), os.path.join(results_dir, 'models', f'ubc-ocean-{run_name}.pt'))\n",
    "        wandb.log({f'balanced_acc_cv{cv+1}': balanced_acc})\n",
    "elif CFG['valid_type'] == 'standard':\n",
    "    for cv, (train_index, valid_index) in enumerate(skf.split(X=np.zeros(len(df['label'])), y=df['label'])):\n",
    "        print(f\"Cross-validation fold {cv+1}/{CFG['cv_fold']}\")\n",
    "        df_train = df.iloc[train_index]\n",
    "        df_validation = df.iloc[valid_index]\n",
    "        run_name = f'{run.name}-cv{cv+1}'\n",
    "        model, balanced_acc = train_model(CFG, train_image_dir, train_thumbnail_dir, df_train, df_validation, encode)\n",
    "        balanced_acc_list.append(balanced_acc)\n",
    "        torch.save(model.state_dict(), os.path.join(results_dir, 'models', f'ubc-ocean-{run_name}.pt'))\n",
    "        wandb.log({f'balanced_acc_cv{cv+1}': balanced_acc})\n",
    "wandb.log({f'mean_balanced_acc': np.mean(balanced_acc_list)})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:45<00:00,  1.33s/it]\n",
      "100%|██████████| 34/34 [00:47<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.3301e-05.\n",
      "train loss: 1.5744, test loss: 1.4697, balanced_accuracy: 0.2654\n",
      "\n",
      "Training complete in 1m 33s\n",
      "Final balanced_accuracy: 0.265444\n",
      "\n",
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:55<00:00,  1.63s/it]\n",
      "100%|██████████| 34/34 [00:47<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.5000e-05.\n",
      "train loss: 1.3541, test loss: 1.3650, balanced_accuracy: 0.2941\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:52<00:00,  1.55s/it]\n",
      "100%|██████████| 34/34 [00:47<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "train loss: 1.1822, test loss: 0.8319, balanced_accuracy: 0.6406\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:54<00:00,  1.61s/it]\n",
      "100%|██████████| 34/34 [00:47<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.5000e-05.\n",
      "train loss: 0.9258, test loss: 0.6984, balanced_accuracy: 0.7417\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:54<00:00,  1.62s/it]\n",
      "100%|██████████| 34/34 [00:47<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.6987e-06.\n",
      "train loss: 0.7393, test loss: 0.5483, balanced_accuracy: 0.7538\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:52<00:00,  1.55s/it]\n",
      "100%|██████████| 34/34 [00:47<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 0.0000e+00.\n",
      "train loss: 0.6049, test loss: 0.5139, balanced_accuracy: 0.7741\n",
      "\n",
      "Training complete in 8m 29s\n",
      "Final balanced_accuracy: 0.774135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final training on all data\n",
    "model, _ = train_model(CFG, train_image_dir, train_thumbnail_dir, df, df, encode, wandb_log=False)\n",
    "torch.save(model.state_dict(), os.path.join(results_dir, 'models', f'ubc-ocean-{run.name}.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubc-ocean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
