{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaraiadam88\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/latlab/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/latlab/MR/projects/kaggle-ubc-ocean/src/wandb/run-20231130_114838-wtwrj7wd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/naraiadam88/kaggle-ubc-ocean/runs/wtwrj7wd' target=\"_blank\">likely-smoke-297</a></strong> to <a href='https://wandb.ai/naraiadam88/kaggle-ubc-ocean' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/naraiadam88/kaggle-ubc-ocean' target=\"_blank\">https://wandb.ai/naraiadam88/kaggle-ubc-ocean</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/naraiadam88/kaggle-ubc-ocean/runs/wtwrj7wd' target=\"_blank\">https://wandb.ai/naraiadam88/kaggle-ubc-ocean/runs/wtwrj7wd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "\n",
    "from dataset import get_dataloaders, get_tiles_datasets\n",
    "from utils import seed_everything\n",
    "from trainer import Trainer\n",
    "\n",
    "# Params\n",
    "Image.MAX_IMAGE_PIXELS = 1e11\n",
    "CFG = {\n",
    "    'seed': 42,\n",
    "    'cv_fold': 5,\n",
    "    'base_model': 'resnet50',   # resnet18/34/50, efficientnet_b0/b1/b2/b3/b4\n",
    "    'img_size': 512,\n",
    "    'batch_size': 32,\n",
    "    'freeze_epochs': 1,\n",
    "    'epochs': 5,\n",
    "    'base_lr': 1e-4,\n",
    "    'affine_degrees': 0,\n",
    "    'affine_translate': None,\n",
    "    'affine_scale': None,\n",
    "    'dataloader_num_workers': 8,\n",
    "    'scheduler_step_size': 2,\n",
    "    'img_color_mean': [0.8708488980328596, 0.75677901508938, 0.8545134911215124],\n",
    "    'img_color_std': [0.08086288591996027, 0.11553960008706814, 0.06914169213328555],\n",
    "    'tile_num': 32,\n",
    "    'optimizer': 'AdamW',\n",
    "    'scheduler': 'StepLR',\n",
    "    'lr_gamma': 0.1,\n",
    "    'sgd_momentum': 0.9,\n",
    "    'tile_set': 'train_tiles_random_2048_p25_outl80'\n",
    "}\n",
    "tags=['torch', 'tiles', 'cv']\n",
    "notes = ''\n",
    "plot_samples = False\n",
    "\n",
    "# Wandb\n",
    "wandb.login(key='1b0401db7513303bdea77fb070097f9d2850cf3b')\n",
    "run = wandb.init(project='kaggle-ubc-ocean', config=CFG, tags=tags, notes=notes)\n",
    "\n",
    "# Label encoder/decoder\n",
    "encode = {'HGSC': 0, 'LGSC': 1, 'EC': 2, 'CC': 3, 'MC': 4}\n",
    "decode = {v: k for k, v in encode.items()}\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Paths\n",
    "root = '/media/latlab/MR/projects/kaggle-ubc-ocean'\n",
    "data_dir = os.path.join(root, 'data')\n",
    "results_dir = os.path.join(root, 'results')\n",
    "train_image_dir = os.path.join(results_dir, CFG['tile_set'])\n",
    "train_csv = '{}_sample{}.csv'.format(CFG['tile_set'], CFG['tile_num'])\n",
    "\n",
    "# Seed\n",
    "seed_everything(CFG['seed'])\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(os.path.join(results_dir, train_csv))\n",
    "df['label'] = df.loc[:,'label'].map(encode)\n",
    "\n",
    "# Functions\n",
    "def train_model(CFG, train_image_dir, df_train, df_validation, encode, wandb_log=False):\n",
    "    # Data loaders\n",
    "    datasets = get_tiles_datasets(CFG, train_image_dir, df_train, df_validation)\n",
    "    dataloaders = get_dataloaders(CFG, datasets)\n",
    "\n",
    "    # Model definition\n",
    "    model = models.get_model(CFG['base_model'], weights='DEFAULT').to(device)\n",
    "\n",
    "    # Freeze all parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Replace the last fully-connected layer\n",
    "    if CFG['base_model'].startswith('resnet'):\n",
    "        model.fc = nn.Linear(in_features=model.fc.in_features, out_features=len(encode)).to(device)\n",
    "    elif CFG['base_model'].startswith('efficientnet'):\n",
    "        model.classifier = nn.Linear(in_features=model.classifier[1].in_features, out_features=len(encode)).to(device)\n",
    "    \n",
    "    # Loss function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Optimizer\n",
    "    if CFG['optimizer'] == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=CFG['base_lr'], momentum=CFG['sgd_momentum'])\n",
    "    elif CFG['optimizer'] == 'AdamW':\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=CFG['base_lr'])\n",
    "    elif CFG['optimizer'] == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=CFG['base_lr'])\n",
    "    \n",
    "    # Scheduler\n",
    "    if CFG['scheduler'] == 'StepLR':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=CFG['scheduler_step_size'], gamma=CFG['lr_gamma'], verbose=True)\n",
    "    elif CFG['scheduler'] == 'CyclicLR':\n",
    "        scheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr=CFG['base_lr'], max_lr=CFG['base_lr']*5,\n",
    "                                                step_size_up=5, cycle_momentum=False, mode='triangular2', verbose=True)\n",
    "    elif CFG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG['epochs']+CFG['freeze_epochs'], verbose=True)\n",
    "    elif CFG['scheduler'] == 'OneCycleLR':\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=CFG['base_lr'], total_steps=CFG['epochs']+CFG['freeze_epochs'], verbose=True)\n",
    "\n",
    "    # Training\n",
    "    trainer = Trainer(model, dataloaders, loss_fn, optimizer, scheduler, device, metric='balanced_accuracy', wandb_log=wandb_log)\n",
    "    model, _ = trainer.train_epochs(num_epochs=CFG['freeze_epochs'])\n",
    "    trainer.unfreeze()\n",
    "    model, balanced_acc = trainer.train_epochs(num_epochs=CFG['epochs'])\n",
    "    return model, balanced_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training data\n",
    "if plot_samples:\n",
    "    dataloaders = get_dataloaders(CFG, get_tiles_datasets(CFG, train_image_dir, df, df))\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloaders['train']):\n",
    "            plt.figure(figsize=(np.ceil(len(X)/2), 12))\n",
    "            for i in range(len(X)):\n",
    "                plt.subplot(int(np.ceil(len(X)/6)), 6, i+1)\n",
    "                img_data = X[i].permute(1, 2, 0).cpu().numpy()\n",
    "                plt.imshow(img_data)\n",
    "                plt.title(f'{decode[y[i].item()]}')\n",
    "            if batch >= 1:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation fold 1/5\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 239/812 [01:21<03:15,  2.93it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/latlab/MR/projects/kaggle-ubc-ocean/src/pytorch_tiles_cv.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.200.91.54/media/latlab/MR/projects/kaggle-ubc-ocean/src/pytorch_tiles_cv.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m df_validation \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[valid_index]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.200.91.54/media/latlab/MR/projects/kaggle-ubc-ocean/src/pytorch_tiles_cv.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m run_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrun\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m-cv\u001b[39m\u001b[39m{\u001b[39;00mcv\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.200.91.54/media/latlab/MR/projects/kaggle-ubc-ocean/src/pytorch_tiles_cv.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m model, balanced_acc \u001b[39m=\u001b[39m train_model(CFG, train_image_dir, df_train, df_validation, encode)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.200.91.54/media/latlab/MR/projects/kaggle-ubc-ocean/src/pytorch_tiles_cv.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m balanced_acc_list\u001b[39m.\u001b[39mappend(balanced_acc)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.200.91.54/media/latlab/MR/projects/kaggle-ubc-ocean/src/pytorch_tiles_cv.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(results_dir, \u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mubc-ocean-\u001b[39m\u001b[39m{\u001b[39;00mrun_name\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;32m/media/latlab/MR/projects/kaggle-ubc-ocean/src/pytorch_tiles_cv.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.200.91.54/media/latlab/MR/projects/kaggle-ubc-ocean/src/pytorch_tiles_cv.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=112'>113</a>\u001b[0m \u001b[39m# Training\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.200.91.54/media/latlab/MR/projects/kaggle-ubc-ocean/src/pytorch_tiles_cv.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=113'>114</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model, dataloaders, loss_fn, optimizer, scheduler, device, metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbalanced_accuracy\u001b[39m\u001b[39m'\u001b[39m, wandb_log\u001b[39m=\u001b[39mwandb_log)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B10.200.91.54/media/latlab/MR/projects/kaggle-ubc-ocean/src/pytorch_tiles_cv.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=114'>115</a>\u001b[0m model, _ \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain_epochs(num_epochs\u001b[39m=\u001b[39;49mCFG[\u001b[39m'\u001b[39;49m\u001b[39mfreeze_epochs\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.200.91.54/media/latlab/MR/projects/kaggle-ubc-ocean/src/pytorch_tiles_cv.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=115'>116</a>\u001b[0m trainer\u001b[39m.\u001b[39munfreeze()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.200.91.54/media/latlab/MR/projects/kaggle-ubc-ocean/src/pytorch_tiles_cv.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=116'>117</a>\u001b[0m model, balanced_acc \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mtrain_epochs(num_epochs\u001b[39m=\u001b[39mCFG[\u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/media/latlab/MR/projects/kaggle-ubc-ocean/src/trainer/trainer.py:36\u001b[0m, in \u001b[0;36mTrainer.train_epochs\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m10\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     37\u001b[0m test_loss, metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest()\n\u001b[1;32m     38\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m/media/latlab/MR/projects/kaggle-ubc-ocean/src/trainer/trainer.py:58\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     57\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 58\u001b[0m \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m tqdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataloader, total\u001b[39m=\u001b[39mnum_batches):\n\u001b[1;32m     59\u001b[0m     X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), y\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     61\u001b[0m     \u001b[39m# Compute prediction error\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ubc-ocean/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ubc-ocean/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/ubc-ocean/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ubc-ocean/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m   1283\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m-> 1284\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1285\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1286\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/ubc-ocean/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ubc-ocean/lib/python3.11/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[1;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/anaconda3/envs/ubc-ocean/lib/python3.11/threading.py:331\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    332\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "skf = StratifiedGroupKFold(n_splits=CFG['cv_fold'], random_state=CFG['seed'], shuffle=True)\n",
    "balanced_acc_list = []\n",
    "for cv, (train_index, valid_index) in enumerate(skf.split(X=np.zeros(len(df['label'])), y=df['label'], groups=df['orig_image_id'])):\n",
    "    print(f\"Cross-validation fold {cv+1}/{CFG['cv_fold']}\")\n",
    "    df_train = df.iloc[train_index]\n",
    "    df_validation = df.iloc[valid_index]\n",
    "    run_name = f'{run.name}-cv{cv+1}'\n",
    "    model, balanced_acc = train_model(CFG, train_image_dir, df_train, df_validation, encode)\n",
    "    balanced_acc_list.append(balanced_acc)\n",
    "    torch.save(model.state_dict(), os.path.join(results_dir, 'models', f'ubc-ocean-{run_name}.pt'))\n",
    "    wandb.log({f'balanced_acc_cv{cv+1}': balanced_acc})\n",
    "wandb.log({f'mean_balanced_acc': np.mean(balanced_acc_list)})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final training on all data\n",
    "final_model, _ = train_model(CFG, train_image_dir, df, df, encode, wandb_log=False)\n",
    "torch.save(final_model.state_dict(), os.path.join(results_dir, 'models', f'ubc-ocean-{run.name}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "import warnings\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "datasets = get_tiles_datasets(CFG, train_image_dir, df_train, df_validation)\n",
    "dataloaders = get_dataloaders(CFG, datasets)\n",
    "y_list = []\n",
    "pred_list = []\n",
    "loss_list = []\n",
    "metric = 0\n",
    "with torch.no_grad():\n",
    "    for X, y in dataloaders['validation']:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        outputs = model(X)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        y_list.append(y.cpu().numpy())\n",
    "        pred_list.append(preds.cpu().numpy())\n",
    "        loss_list.append(loss.cpu().numpy())\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore', category=UserWarning)\n",
    "            metric += balanced_accuracy_score(y.cpu().numpy(), preds.cpu().numpy())\n",
    "metric /= len(dataloaders['validation'])\n",
    "y_list = np.concatenate(y_list)\n",
    "pred_list = np.concatenate(pred_list)\n",
    "loss_list = np.concatenate(loss_list)\n",
    "\n",
    "from ext.pretty_confusion_matrix import pp_matrix\n",
    "cm = confusion_matrix(y_list, pred_list)\n",
    "df_cm = pd.DataFrame(cm, index=encode.keys(), columns=encode.keys())\n",
    "pp_matrix(df_cm, pred_val_axis='x', cmap='Oranges', figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top k losses\n",
    "k = 10\n",
    "topk_loss_idx = list(loss_list.argsort()[-k:])\n",
    "with torch.no_grad():\n",
    "    for b, (X, y) in enumerate(dataloaders['validation']):\n",
    "        for bi in range(len(X)):\n",
    "            i = b * CFG['batch_size'] + bi\n",
    "            if i not in topk_loss_idx:\n",
    "                continue\n",
    "            plt.figure()\n",
    "            plt.imshow(X[bi].permute(1, 2, 0))\n",
    "            plt.title(f'loss: {loss_list[i]:.4f}, label: {decode[y_list[i]]}, pred: {decode[pred_list[i]]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubc-ocean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
